### Abstract
In this project, we implemented a Softmax categorization algorithm with Stochastic Gradient Descent with
Momentum. We then investigated how performance changes when the hyper parameters of Learning Rate α,
Batch Size γ and Momentum magnitude β were changed. Finally, we compared the performance to a selection
of models, including Gaussian Naive Bayes, K-Nearest Neighbours and Decision Trees. It was found that KNearest Neighbors resulted in high training and validation accuracies on the Digits dataset, while Naive Bayes
was the superior model for the Credits dataset.


